# -*- coding: utf-8 -*-
"""
è®­ç»ƒç›¸å…³APIç«¯ç‚¹
ç”¨é€”ï¼šæä¾›æ¨¡å‹è®­ç»ƒã€æ•°æ®ä¸‹è½½ç­‰åŠŸèƒ½çš„RESTfulæ¥å£
"""

from flask import Blueprint, request, jsonify
import threading
import time
from typing import Dict, Any
import traceback

from ..scripts.dataset_loader import DatasetLoader
from ..training.trainer import ModelTrainer
from ..utils.config import Config

# åˆ›å»ºè“å›¾
training_bp = Blueprint('training', __name__, url_prefix='/training')

# å…¨å±€å˜é‡å­˜å‚¨è®­ç»ƒçŠ¶æ€
training_status = {
    "is_training": False,
    "current_task": None,
    "progress": 0,
    "message": "",
    "error": None,
    "results": None
}

# æ•°æ®ä¸‹è½½çŠ¶æ€
download_status = {
    "is_downloading": False,
    "language": None,
    "progress": 0,
    "message": "",
    "error": None,
    "completed": False
}

@training_bp.route('/datasets/download', methods=['POST'])
def download_dataset():
    """
    ä¸‹è½½æ•°æ®é›†ç«¯ç‚¹
    è¯·æ±‚ä½“: {"language": "chinese/english/both", "max_samples": å¯é€‰}
    """
    global download_status
    
    try:
        data = request.get_json()
        if not data or "language" not in data:
            return jsonify({
                "status": "error",
                "message": "è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«'language'å­—æ®µ"
            }), 400
        
        language = data["language"]
        max_samples = data.get("max_samples", None)
        
        if language not in ["chinese", "english", "both"]:
            return jsonify({
                "status": "error",
                "message": "è¯­è¨€ç±»å‹å¿…é¡»æ˜¯ chineseã€english æˆ– both"
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ä¸‹è½½
        if download_status["is_downloading"]:
            return jsonify({
                "status": "error",
                "message": "æ•°æ®é›†ä¸‹è½½æ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•"
            }), 409
        
        # å¯åŠ¨åå°ä¸‹è½½ä»»åŠ¡
        def download_task():
            global download_status
            try:
                download_status.update({
                    "is_downloading": True,
                    "language": language,
                    "progress": 0,
                    "message": "å¼€å§‹ä¸‹è½½æ•°æ®é›†...(æ”¯æŒHugging Face + Kaggleå¤šæ•°æ®æº)",
                    "error": None,
                    "completed": False
                })
                
                if language == "both":
                    # ä¸‹è½½ä¸­è‹±æ–‡æ•°æ®é›†
                    languages = ["chinese", "english"]
                    for i, lang in enumerate(languages):
                        download_status["message"] = f"æ­£åœ¨ä¸‹è½½{lang}æ•°æ®é›†..."
                        download_status["progress"] = int((i / len(languages)) * 50)
                        
                        loader = DatasetLoader(language=lang)
                        train_data, val_data, test_data = loader.get_processed_data(max_samples)
                        
                        download_status["progress"] = int(((i + 1) / len(languages)) * 100)
                else:
                    # ä¸‹è½½å•ä¸€è¯­è¨€æ•°æ®é›†
                    download_status["message"] = f"æ­£åœ¨ä¸‹è½½{language}æ•°æ®é›†..."
                    download_status["progress"] = 50
                    
                    loader = DatasetLoader(language=language)
                    train_data, val_data, test_data = loader.get_processed_data(max_samples)
                    
                    download_status["progress"] = 100
                
                download_status.update({
                    "is_downloading": False,
                    "message": "æ•°æ®é›†ä¸‹è½½å®Œæˆ",
                    "completed": True
                })
                
            except Exception as e:
                download_status.update({
                    "is_downloading": False,
                    "error": str(e),
                    "message": f"ä¸‹è½½å¤±è´¥: {str(e)}"
                })
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ä¸‹è½½
        thread = threading.Thread(target=download_task)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            "status": "success",
            "message": "æ•°æ®é›†ä¸‹è½½å·²å¯åŠ¨ï¼Œè¯·ä½¿ç”¨çŠ¶æ€æ¥å£æŸ¥çœ‹è¿›åº¦"
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"å¯åŠ¨ä¸‹è½½å¤±è´¥: {str(e)}"
        }), 500

@training_bp.route('/datasets/status', methods=['GET'])
def get_download_status():
    """
    è·å–æ•°æ®ä¸‹è½½çŠ¶æ€
    """
    return jsonify({
        "status": "success",
        "data": download_status
    })

@training_bp.route('/models/train', methods=['POST'])
def train_model():
    """
    å¯åŠ¨æ¨¡å‹è®­ç»ƒç«¯ç‚¹
    è¯·æ±‚ä½“: {
        "model_type": "textcnn/bilstm/bert",
        "language": "chinese/english",
        "epochs": å¯é€‰,
        "batch_size": å¯é€‰,
        "learning_rate": å¯é€‰
    }
    """
    global training_status
    
    try:
        data = request.get_json()
        if not data or "model_type" not in data:
            return jsonify({
                "status": "error",
                "message": "è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«'model_type'å­—æ®µ"
            }), 400
        
        model_type = data["model_type"]
        language = data.get("language", "chinese")
        epochs = data.get("epochs", Config.TRAINING_CONFIG["num_epochs"])
        batch_size = data.get("batch_size", Config.TRAINING_CONFIG["batch_size"])
        learning_rate = data.get("learning_rate", Config.TRAINING_CONFIG["learning_rate"])
        
        # éªŒè¯å‚æ•°
        if model_type not in ["textcnn", "bilstm", "bert"]:
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹ç±»å‹å¿…é¡»æ˜¯ textcnnã€bilstm æˆ– bert"
            }), 400
        
        if language not in ["chinese", "english"]:
            return jsonify({
                "status": "error",
                "message": "è¯­è¨€ç±»å‹å¿…é¡»æ˜¯ chinese æˆ– english"
            }), 400
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è®­ç»ƒ
        if training_status["is_training"]:
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•"
            }), 409
        
        # å¯åŠ¨åå°è®­ç»ƒä»»åŠ¡
        def training_task():
            global training_status
            try:
                training_status.update({
                    "is_training": True,
                    "current_task": f"è®­ç»ƒ{model_type}æ¨¡å‹",
                    "progress": 0,
                    "message": "åˆå§‹åŒ–è®­ç»ƒå™¨...",
                    "error": None,
                    "results": None
                })
                
                # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨ï¼Œå¸¦è¿›åº¦å›è°ƒ
                def progress_callback(progress: int, message: str):
                    training_status["progress"] = progress
                    training_status["message"] = message
                
                from ..training.trainer_manager import TrainerManager
                trainer_manager = TrainerManager(
                    model_type=model_type, 
                    language=language, 
                    progress_callback=progress_callback
                )
                
                # æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿
                results = trainer_manager.full_training_pipeline(
                    epochs=epochs,
                    learning_rate=learning_rate,
                    max_samples=1000  # ä¸ºäº†å¿«é€Ÿæµ‹è¯•ï¼Œé™åˆ¶æ ·æœ¬æ•°é‡
                )
                
                # è®­ç»ƒå®Œæˆ
                training_status.update({
                    "is_training": False,
                    "progress": 100,
                    "message": "è®­ç»ƒå®Œæˆ",
                    "results": {
                        "model_type": results['model_type'],
                        "language": results['language'],
                        "epochs": results['epochs'],
                        "best_val_accuracy": results['best_val_accuracy'],
                        "final_train_accuracy": results['final_train_accuracy'],
                        "final_val_accuracy": results['final_val_accuracy'],
                        "test_accuracy": results['test_results']['accuracy'],
                        "model_path": results['model_path'],
                        "early_stopped": results.get('early_stopped', False)
                    }
                })
                
                print(f"âœ… {model_type}æ¨¡å‹è®­ç»ƒå®Œæˆ!")
                print(f"ğŸ“Š æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {results['best_val_accuracy']:.4f}")
                print(f"ğŸ“Š æµ‹è¯•å‡†ç¡®ç‡: {results['test_results']['accuracy']:.4f}")
                print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜è·¯å¾„: {results['model_path']}")
                
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                print(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
                print(f"è¯¦ç»†é”™è¯¯: {error_detail}")
                
                training_status.update({
                    "is_training": False,
                    "error": str(e),
                    "message": f"è®­ç»ƒå¤±è´¥: {str(e)}"
                })
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨è®­ç»ƒ
        thread = threading.Thread(target=training_task)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            "status": "success",
            "message": "æ¨¡å‹è®­ç»ƒå·²å¯åŠ¨ï¼Œè¯·ä½¿ç”¨çŠ¶æ€æ¥å£æŸ¥çœ‹è¿›åº¦"
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {str(e)}"
        }), 500

@training_bp.route('/models/status', methods=['GET'])
def get_training_status():
    """
    è·å–è®­ç»ƒçŠ¶æ€
    """
    return jsonify({
        "status": "success",
        "data": training_status
    })

@training_bp.route('/models/list', methods=['GET'])
def list_trained_models():
    """
    åˆ—å‡ºå·²è®­ç»ƒçš„æ¨¡å‹
    """
    try:
        models = []
        models_dir = Config.MODELS_DIR
        
        if models_dir.exists():
            for model_file in models_dir.glob("*.pth"):
                # è§£ææ¨¡å‹æ–‡ä»¶å
                filename = model_file.stem
                parts = filename.split("_")
                if len(parts) >= 2:
                    model_type = parts[0]
                    language = parts[1]
                    
                    models.append({
                        "model_type": model_type,
                        "language": language,
                        "filename": model_file.name,
                        "size": model_file.stat().st_size,
                        "created_time": model_file.stat().st_ctime
                    })
        
        return jsonify({
            "status": "success",
            "data": {
                "models": models,
                "total_count": len(models)
            }
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        }), 500

@training_bp.route('/datasets/info', methods=['GET'])
def get_datasets_info():
    """
    è·å–æ•°æ®é›†ä¿¡æ¯
    """
    try:
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²ä¸‹è½½
        def check_dataset_downloaded(language):
            """æ£€æŸ¥æŒ‡å®šè¯­è¨€çš„æ•°æ®é›†æ˜¯å¦å·²ä¸‹è½½"""
            datasets_dir = Config.DATASETS_DIR
            if not datasets_dir.exists():
                return False
            
            dataset_name = Config.DATASETS[language]
            
            # æ ¹æ®ä¸åŒæ•°æ®é›†æ£€æŸ¥ç‰¹å®šæ–‡ä»¶å¤¹
            if language == "chinese":
                # ä¸­æ–‡æ•°æ®é›†ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ seamew æˆ– ChnSentiCorp ç›¸å…³æ–‡ä»¶å¤¹
                seamew_dirs = list(datasets_dir.glob("**/seamew*")) + list(datasets_dir.glob("**/ChnSentiCorp*"))
                return len(seamew_dirs) > 0
            elif language == "english":
                # è‹±æ–‡æ•°æ®é›†ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ imdb ç›¸å…³æ–‡ä»¶å¤¹
                imdb_dirs = list(datasets_dir.glob("**/imdb*")) + list(datasets_dir.glob("**/IMDb*"))
                return len(imdb_dirs) > 0
            
            return False
        
        info = {
            "available_datasets": [
                {
                    "language": "chinese",
                    "name": "ChnSentiCorp",
                    "description": "ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ•°æ®é›†ï¼ŒåŒ…å«é…’åº—ã€ä¹¦ç±ã€é¤é¥®è¯„è®º",
                    "size": "çº¦12,000æ¡",
                    "source": "Hugging Face",
                    "downloaded": check_dataset_downloaded("chinese")
                },
                {
                    "language": "english", 
                    "name": "IMDb Movie Reviews",
                    "description": "è‹±æ–‡ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ææ•°æ®é›†",
                    "size": "50,000æ¡",
                    "source": "Hugging Face",
                    "downloaded": check_dataset_downloaded("english")
                }
            ],
            "supported_languages": ["chinese", "english"],
            "data_directory": str(Config.DATASETS_DIR)
        }
        
        return jsonify({
            "status": "success",
            "data": info
        })
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {str(e)}"
        }), 500 